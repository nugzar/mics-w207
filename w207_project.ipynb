{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this competition is to predict a Windows machine’s probability of getting infected by various families of malware, based on different properties of that machine. The telemetry data containing these properties and the machine infections was generated by combining heartbeat and threat reports collected by Microsoft's endpoint protection solution, Windows Defender.\n",
    "\n",
    "Each row in this dataset corresponds to a machine, uniquely identified by a MachineIdentifier. HasDetections is the ground truth and indicates that Malware was detected on the machine. Using the information and labels in train.csv, you must predict the value for HasDetections for each machine in test.csv.\n",
    "\n",
    "The sampling methodology used to create this dataset was designed to meet certain business constraints, both in regards to user privacy as well as the time period during which the machine was running. Malware detection is inherently a time-series problem, but it is made complicated by the introduction of new machines, machines that come online and offline, machines that receive patches, machines that receive new operating systems, etc. While the dataset provided here has been roughly split by time, the complications and sampling requirements mentioned above may mean you may see imperfect agreement between your cross validation, public, and private scores! Additionally, this dataset is not representative of Microsoft customers’ machines in the wild; it has been sampled to include a much larger proportion of malware machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, linear_model\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up display area to show dataframe in jupyter qtconsole\n",
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to explicitly specify data types when reading csv, otherwise it is very memory consuming\n",
    "# and we will get the warning \"Specify dtype option on import or set low_memory=False\"\n",
    "# So, we will manually defined the data types\n",
    "\n",
    "# P.S. I have loaded the sample data and exported train_data.dtypes\n",
    "# these are the data types for fast loading\n",
    "\n",
    "datatypes = {\n",
    "    'ProductName': np.int8,\n",
    "    'IsBeta': np.int8,\n",
    "    'RtpStateBitfield': np.int64,\n",
    "    'IsSxsPassiveMode': np.int8,\n",
    "    'AVProductStatesIdentifier': np.int64,\n",
    "    'AVProductsInstalled': np.int64,\n",
    "    'AVProductsEnabled': np.int64,\n",
    "    'CountryIdentifier': np.int64,\n",
    "    'CityIdentifier': np.int64,\n",
    "    'OrganizationIdentifier': np.int64,\n",
    "    'GeoNameIdentifier': np.int64,\n",
    "    'LocaleEnglishNameIdentifier': np.int64,\n",
    "    'Platform': np.int16,\n",
    "    'Processor': np.int8,\n",
    "    'OsSuite': np.int64,\n",
    "    'OsPlatformSubRelease': np.int16,\n",
    "    'SkuEdition': np.int8,\n",
    "    'IsProtected': np.int64,\n",
    "    'AutoSampleOptIn': np.int8,\n",
    "    'SMode': np.int64,\n",
    "    'IeVerIdentifier': np.int64,\n",
    "    'SmartScreen': np.int8,\n",
    "    'Firewall': np.int64,\n",
    "    'UacLuaenable': np.int64,\n",
    "    'Census_MDC2FormFactor': np.int8,\n",
    "    'Census_DeviceFamily': np.int8,\n",
    "    'Census_OEMNameIdentifier': np.int64,\n",
    "    'Census_ProcessorManufacturerIdentifier': np.int64,\n",
    "    'Census_ProcessorModelIdentifier': np.int64,\n",
    "    'Census_PrimaryDiskTotalCapacity': np.float64,\n",
    "    'Census_PrimaryDiskTypeName': np.int8,\n",
    "    'Census_SystemVolumeTotalCapacity': np.float64,\n",
    "    'Census_HasOpticalDiskDrive': np.int8,\n",
    "    'Census_TotalPhysicalRAM': np.float64,\n",
    "    'Census_ChassisTypeName': np.int8,\n",
    "    'Census_InternalPrimaryDiagonalDisplaySizeInInches': np.float64,\n",
    "    'Census_InternalPrimaryDisplayResolutionHorizontal': np.int64,\n",
    "    'Census_InternalPrimaryDisplayResolutionVertical': np.int64,\n",
    "    'Census_PowerPlatformRoleName': np.int8,\n",
    "    'Census_InternalBatteryNumberOfCharges': np.float64,\n",
    "    'Census_OSArchitecture': np.int8,\n",
    "    'Census_OSBranch': np.int8,\n",
    "    'Census_OSBuildNumber': np.int64,\n",
    "    'Census_OSBuildRevision': np.int64,\n",
    "    'Census_OSEdition': np.int8,\n",
    "    'Census_OSInstallTypeName': np.int8,\n",
    "    'Census_OSInstallLanguageIdentifier': np.int64,\n",
    "    'Census_OSUILocaleIdentifier': np.int64,\n",
    "    'Census_OSWUAutoUpdateOptionsName': np.int8,\n",
    "    'Census_IsPortableOperatingSystem': np.int8,\n",
    "    'Census_GenuineStateName': np.int8,\n",
    "    'Census_ActivationChannel': np.int8,\n",
    "    'Census_IsFlightsDisabled': np.int64,\n",
    "    'Census_FlightRing': np.int8,\n",
    "    'Census_ThresholdOptIn': np.int64,\n",
    "    'Census_FirmwareManufacturerIdentifier': np.int64,\n",
    "    'Census_FirmwareVersionIdentifier': np.int64,\n",
    "    'Census_IsSecureBootEnabled': np.int8,\n",
    "    'Census_IsWIMBootEnabled': np.int64,\n",
    "    'Census_IsVirtualDevice': np.int64,\n",
    "    'Census_IsTouchEnabled': np.int8,\n",
    "    'Census_IsPenCapable': np.int8,\n",
    "    'Census_IsAlwaysOnAlwaysConnectedCapable': np.int64,\n",
    "    'Wdft_IsGamer': np.int64,\n",
    "    'Wdft_RegionIdentifier': np.int64,\n",
    "    'EngineVersion_1': np.int64,\n",
    "    'EngineVersion_2': np.int64,\n",
    "    'EngineVersion_3': np.int64,\n",
    "    'EngineVersion_4': np.int64,\n",
    "    'AppVersion_1': np.int64,\n",
    "    'AppVersion_2': np.int64,\n",
    "    'AppVersion_3': np.int64,\n",
    "    'AppVersion_4': np.int64,\n",
    "    'AvSigVersion_1': np.int64,\n",
    "    'AvSigVersion_2': np.float64,\n",
    "    'AvSigVersion_3': np.int64,\n",
    "    'AvSigVersion_4': np.int64,\n",
    "    'OsVer_1': np.int64,\n",
    "    'OsVer_2': np.int64,\n",
    "    'OsVer_3': np.int64,\n",
    "    'OsVer_4': np.int64,\n",
    "    'OsBuildLab_1': np.int64,\n",
    "    'OsBuildLab_2': np.int64,\n",
    "    'OsBuildLab_3': np.int8,\n",
    "    'OsBuildLab_4': np.int8,\n",
    "    'OsBuildLab_5': np.int64,\n",
    "    'OsBuildLab_6': np.int64,\n",
    "    'Census_OSVersion_1': np.int64,\n",
    "    'Census_OSVersion_2': np.int64,\n",
    "    'Census_OSVersion_3': np.int64,\n",
    "    'Census_OSVersion_4': np.int64,\n",
    "    'CORE': np.int64,\n",
    "    'EDUCATION': np.int64,\n",
    "    'PRO': np.int64,\n",
    "    'ENTERPRISE': np.int64,\n",
    "    'CLOUD': np.int64,\n",
    "    'SERVER': np.int64,\n",
    "    'EVALUATION': np.int64,\n",
    "    'ScreenProportion': np.float64,\n",
    "    'ScreenDimensions': np.int64,\n",
    "    'CapacityDifference': np.float64,\n",
    "    'CapacityRatio': np.float64,\n",
    "    'RAMByCores': np.float64,\n",
    "    'HasDetections': np.int8\n",
    "}\n",
    "\n",
    "full_features = pd.read_csv('./csv/full_v11_engineered.csv', dtype=datatypes, index_col=\"MachineIdentifier\")\n",
    "full_labels = full_features[\"HasDetections\"]\n",
    "\n",
    "# Dropping labels [\"HasDetections\"] from training dataset\n",
    "full_features = full_features.drop([\"HasDetections\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (full_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see some details of the loaded data\n",
    "full_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCA(n_components=10)\n",
    "pca_results = np.array(model.fit_transform(full_features))\n",
    "\n",
    "# We need cumulative sums by components\n",
    "variances = model.explained_variance_ratio_.cumsum()\n",
    "\n",
    "for k in range(len(variances)):\n",
    "    print (\"k =\", k + 1, \" Variance =\", variances[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "# np.random.seed(0)\n",
    "shuffle = np.random.permutation(np.arange(full_features.shape[0]))\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = \\\n",
    "    train_test_split(full_features.values[shuffle], full_labels.values[shuffle], train_size=0.80)\n",
    "\n",
    "print (train_features.shape, test_features.shape, train_labels.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_features)\n",
    "\n",
    "normalized_train_features = scaler.transform(train_features)\n",
    "normalized_test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA = 2 gives us 0.999+ accuracy, but let's choose at least 10 for number of components\n",
    "model = PCA(n_components=10)\n",
    "\n",
    "train_pca = np.array(model.fit_transform(normalized_train_features))\n",
    "test_pca = np.array(model.transform(normalized_test_features))\n",
    "\n",
    "print (train_pca.shape, test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCA(n_components=2)\n",
    "\n",
    "train_pca_visual = np.array(model.fit_transform(normalized_train_features))\n",
    "\n",
    "# when train_label == 1, then malware was detected\n",
    "# when train_label == 0, malware was NOT detected\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(train_pca_visual[:,0][train_labels==0], train_pca_visual[:,1][train_labels==0], 'bo', markersize=1)\n",
    "plt.plot(train_pca_visual[:,0][train_labels==1], train_pca_visual[:,1][train_labels==1], 'ro', markersize=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(2):\n",
    "    color = 'bo' if i == 0 else 'ro'\n",
    "    title = \"Not detected data visualization\" if i == 0 else \"Detected data visualization\"\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.plot(train_pca_visual[:,0][train_labels==i], train_pca_visual[:,1][train_labels==i], color, markersize=1)\n",
    "    plt.title(title, fontsize = 15)\n",
    "    plt.ylim(train_pca_visual[:,1].min(), train_pca_visual[:,1].max())\n",
    "    plt.xlim(train_pca_visual[:,0].min(), train_pca_visual[:,0].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply k-means + PCA + plot\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "plot_data_length = 200000\n",
    "colors = ['navy', 'turquoise', 'darkorange', 'red', 'purple', 'green', 'black']\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(10,10))\n",
    "\n",
    "for k in range(2,6):\n",
    "    # Fit the training data to a k-means clustering estimator model\n",
    "    kmeans = KMeans(n_clusters=k).fit(train_pca[:plot_data_length])\n",
    "\n",
    "    # Retrieve the labels assigned to each training sample\n",
    "    kmeans_y = kmeans.labels_\n",
    "\n",
    "    for color, cat in zip(colors, range(k)):\n",
    "        p = ax[0 if k < 4 else 1,k % 2]\n",
    "        p.scatter(train_pca[:plot_data_length][kmeans_y==cat, 0],\n",
    "            train_pca[:plot_data_length][kmeans_y==cat, 1],\n",
    "            color=color, alpha=.8, lw=2, label=cat)\n",
    "        p.legend(loc='best', shadow=False, scatterpoints=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "for s in solvers:\n",
    "    # instantiate the model\n",
    "    logreg = LogisticRegression(solver=s)\n",
    "\n",
    "    # fit the model with data\n",
    "    logreg.fit(train_pca, train_labels)\n",
    "\n",
    "    # store the predicted response values\n",
    "    y_pred = logreg.predict(test_pca)\n",
    "    logreg_accuracy_score = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "    print('PCA = ', train_pca.shape[1], s, 'logreg_accuracy_score', logreg_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    \"HistGradientBoosting\": ske.HistGradientBoostingClassifier(random_state=123),\n",
    "    \"DecisionTree\": tree.DecisionTreeClassifier(max_depth=10,random_state=123),\n",
    "    \"RandomForest\": ske.RandomForestClassifier(n_estimators=50,random_state=123),\n",
    "    \"GradientBoosting\": ske.GradientBoostingClassifier(n_estimators=50,random_state=123),\n",
    "    \"AdaBoost\": ske.AdaBoostClassifier(n_estimators=200,random_state=123),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "print('Testing algorithms using original dataset...\\n')\n",
    "print()\n",
    "for algo in algorithms:\n",
    "    clf = algorithms[algo]\n",
    "    clf.fit(train_features, train_labels)\n",
    "    score = clf.score(test_features, test_labels)\n",
    "    print(\"%s : %f %%\" % (algo, score*100))\n",
    "    results[algo] = score\n",
    "    \n",
    "winner = max(results, key=results.get)\n",
    "print()\n",
    "print(f'Winning algorithm is {winner} with a {results[winner]*100}% accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "print('Testing algorithms using normalized original dataset...\\n')\n",
    "print()\n",
    "for algo in algorithms:\n",
    "    clf = algorithms[algo]\n",
    "    clf.fit(normalized_train_features, train_labels)\n",
    "    score = clf.score(normalized_test_features, test_labels)\n",
    "    print(\"%s : %f %%\" % (algo, score*100))\n",
    "    results[algo] = score\n",
    "    \n",
    "winner = max(results, key=results.get)\n",
    "print()\n",
    "print(f'Winning algorithm is {winner} with a {results[winner]*100}% accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "print('Testing algorithms using PCA...\\n')\n",
    "print()\n",
    "for algo in algorithms:\n",
    "    clf = algorithms[algo]\n",
    "    clf.fit(train_pca, train_labels)\n",
    "    score = clf.score(test_pca, test_labels)\n",
    "    print(\"%s : %f %%\" % (algo, score*100))\n",
    "    results[algo] = score\n",
    "    \n",
    "winner = max(results, key=results.get)\n",
    "print()\n",
    "print(f'Winning algorithm is {winner} with a {results[winner]*100}% accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
